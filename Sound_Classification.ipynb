{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 928025,
          "sourceType": "datasetVersion",
          "datasetId": 500970
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Sound Classification",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skj092/learn_sound_classification/blob/main/Sound_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "chrisfilo_urbansound8k_path = kagglehub.dataset_download('chrisfilo/urbansound8k')\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYOLPRrNnqnt",
        "outputId": "a5b80de4-8774-444b-82f6-bf224e054a6e"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wandb\n",
        "from fastai.callback.wandb import *\n",
        "from dataclasses import dataclass\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Define dataclass for hyperparameters\n",
        "@dataclass\n",
        "class HyperParams:\n",
        "    n_mels: int = 64\n",
        "    n_fft: int = 1024\n",
        "    hop_length: int = 512\n",
        "    fmax: int = 8000  # <--- Added to avoid librosa empty filter warning\n",
        "    batch_size: int = 32\n",
        "    image_size: int = 224\n",
        "    architecture: str = \"resnet18\"\n",
        "    epochs: int = 8\n",
        "    lr: float = 3e-3\n",
        "    debug_epochs: int = 1\n",
        "    debug_lr: float = 1e-3\n",
        "\n",
        "# Init hyperparams\n",
        "hparams = HyperParams()\n",
        "\n",
        "# Control debug mode\n",
        "debug = False\n",
        "\n",
        "# WandB init\n",
        "if not debug:\n",
        "    from google.colab import userdata\n",
        "    key = userdata.get('wandb')\n",
        "    os.environ['WANDB_API_KEY'] = key\n",
        "    wandb.init(project=\"urbansound8k-fastai\", name=\"mel-spectrogram-cnn\", reinit=True)\n",
        "    wandb.config.update(vars(hparams))\n",
        "\n",
        "# Define paths and load metadata\n",
        "path = Path('/kaggle/input/urbansound8k')\n",
        "df = pd.read_csv(path/'UrbanSound8K.csv')\n",
        "\n",
        "# Audio to spectrogram function\n",
        "def audio_to_spectrogram(fn, n_mels=hparams.n_mels, n_fft=hparams.n_fft, hop_length=hparams.hop_length, fmax=hparams.fmax):\n",
        "    y, sr = librosa.load(fn, sr=None)\n",
        "    if fmax is None:\n",
        "        fmax = sr // 2\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length, fmax=fmax)\n",
        "    S_db = librosa.power_to_db(S, ref=np.max)\n",
        "    return S_db\n",
        "\n",
        "def spectrogram_to_image(S_db):\n",
        "    S_db = (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
        "    return np.stack([S_db, S_db, S_db], axis=-1)\n",
        "\n",
        "def get_x(row):\n",
        "    return path/f'fold{row[\"fold\"]}'/row['slice_file_name']\n",
        "\n",
        "def get_y(row):\n",
        "    return row['class']\n",
        "\n",
        "def get_spectrogram(row):\n",
        "    try:\n",
        "        S_db = audio_to_spectrogram(get_x(row))\n",
        "        img = spectrogram_to_image(S_db)\n",
        "        return PILImage.create((img * 255).astype(np.uint8))\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {get_x(row)}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Check for missing files\n",
        "df['file_path'] = df.apply(get_x, axis=1)\n",
        "df['file_exists'] = df['file_path'].apply(lambda x: x.exists())\n",
        "print(f\"Missing files: {df[~df['file_exists']].shape[0]}\")\n",
        "df = df[df['file_exists']].reset_index(drop=True)\n",
        "\n",
        "# Custom splitter\n",
        "def custom_splitter(df):\n",
        "    train_idx = df[df['fold'] != 10].index\n",
        "    valid_idx = df[df['fold'] == 10].index\n",
        "    return train_idx, valid_idx\n",
        "\n",
        "# DataBlock\n",
        "dblock = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_x=get_spectrogram,\n",
        "    get_y=get_y,\n",
        "    splitter=custom_splitter,\n",
        "    item_tfms=Resize(hparams.image_size),\n",
        "    batch_tfms=[*aug_transforms(size=hparams.image_size), Normalize.from_stats(*imagenet_stats)]\n",
        ")\n",
        "\n",
        "# Create DataLoaders\n",
        "dls = dblock.dataloaders(df, bs=hparams.batch_size)\n",
        "print(f\"Training batches: {len(dls.train)}, Validation batches: {len(dls.valid)}\")\n",
        "\n",
        "# Create learner\n",
        "cbs = [] if debug else [WandbCallback()]\n",
        "learn = vision_learner(dls, resnet18, metrics=accuracy, cbs=cbs)\n",
        "\n",
        "# Train\n",
        "if debug:\n",
        "    print(\"Running in DEBUG mode ⚡️\")\n",
        "    learn.fine_tune(hparams.debug_epochs, base_lr=hparams.debug_lr)\n",
        "else:\n",
        "    learn.fine_tune(hparams.epochs, base_lr=hparams.lr)\n",
        "\n",
        "# Evaluate\n",
        "learn.show_results()\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "\n",
        "# Plot confusion matrix (and optionally log to wandb)\n",
        "preds, targs = learn.get_preds()\n",
        "pred_labels = preds.argmax(dim=1)\n",
        "vocab = dls.vocab\n",
        "cm = confusion_matrix(targs, pred_labels)\n",
        "\n",
        "# Plot using sklearn\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=vocab)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "disp.plot(ax=ax, xticks_rotation=90, cmap=\"Blues\", colorbar=True)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "\n",
        "# Log to wandb if not debug\n",
        "if not debug:\n",
        " wandb.log({\"confusion_matrix\": wandb.Image(fig)})\n",
        "\n",
        "plt.close(fig)\n",
        "\n",
        "# Export model\n",
        "learn.export('urbansound8k_model.pkl')\n",
        "\n",
        "# Finish wandb run\n",
        "if not debug:\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T08:14:57.408182Z",
          "iopub.execute_input": "2025-07-04T08:14:57.408838Z",
          "iopub.status.idle": "2025-07-04T08:29:40.622032Z",
          "shell.execute_reply.started": "2025-07-04T08:14:57.408807Z",
          "shell.execute_reply": "2025-07-04T08:29:40.621217Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "YsyjPdu3nqnu",
        "outputId": "3bb06c1b-e339-4846-8e19-99da5d755192"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/kaggle/working/wandb/run-20250704_100420-d10q9f9c</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/skj092/urbansound8k-fastai/runs/d10q9f9c' target=\"_blank\">mel-spectrogram-cnn</a></strong> to <a href='https://wandb.ai/skj092/urbansound8k-fastai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/skj092/urbansound8k-fastai' target=\"_blank\">https://wandb.ai/skj092/urbansound8k-fastai</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/skj092/urbansound8k-fastai/runs/d10q9f9c' target=\"_blank\">https://wandb.ai/skj092/urbansound8k-fastai/runs/d10q9f9c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing files: 0\n",
            "Training batches: 246, Validation batches: 27\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.889669</td>\n",
              "      <td>1.339084</td>\n",
              "      <td>0.571087</td>\n",
              "      <td>01:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='0' class='' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/8 00:00&lt;?]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "      <progress value='132' class='' max='246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      53.66% [132/246 00:32&lt;00:28 1.3823]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-_u7oeP04TVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}